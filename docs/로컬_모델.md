
# 로컬 AI에 대한 사용 가이드
## 1. STT 음성모델
    음성을 텍스트로 변환하기 위해 로컬환경에 대한 세팅을 설명한다.

    Nightmare\python\transcription\main.py 코드를 참조한다. 
    자세한 내용은 링크 참조 https://github.com/openai/whisper 
    open ai의 whisper 모델과 fastAPI를 사용하여 
    코드는 localhost:8000로 서비스되게 작성되어있다.
    이후 tbm_sm_cnf테이블에 아래 sql을 insert한다. 

```sql
INSERT INTO `tbm_sm_cnf` (`ID`, `GROUP`, `KEY`, `VALUE`, `FST_REG_DT`, `FNL_UPD_DT`, `CNF_CMF_1`, `CNF_CMF_2`, `CNF_CMF_3`, `CNF_CMF_4`, `CNF_CMF_5`, `CNF_CMF_6`, `CNF_CMF_7`, `CNF_CMF_8`, `CNF_CMF_9`, `CNF_CMF_10`, `USE_YN`) VALUES (9, 'whisper', 'TRANSLATE', 'http://localhost:8000/audio/transcriptions2', '2024-06-23 01:20:48', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'Y');
```

    프로그램에서는 UserConf.properties에서 whisper를 추가하면 적용된다.
```UserConf.properties

    ## whisper 모델 사용시..
    ai.speech.to.text.group=whisper
    ai.speech.to.text.key=TRANSLATE

    ## OPEN AI 사용시..
    ai.speech.to.text.group=OPEN_AI
    ai.speech.to.text.key=TRANSLATE2
```

## 2. OLLAMA
    로컬 생성형 AI로 ollama가 있다고 아래 내용은 ollama를 사용하기 위한 세팅을 설명한다.

    인공지능 AI 모델 window 버젼을 사용한다. ollama의 기본 포트는 11434이며, llama 모델을 사용한다.
    https://ollama.com/
    
    설치가 완료되면 아래 명령어르 AI를 실행하면 llama3 모델을 다운 및 실행한다.
```cmd
    ollama run llama3
```

    어플리케이션에 연동하기 위해선 아래 데이터를 삽입한다.
```sql
INSERT INTO `tbm_sm_cnf` (`ID`, `GROUP`, `KEY`, `VALUE`, `FST_REG_DT`, `FNL_UPD_DT`, `CNF_CMF_1`, `CNF_CMF_2`, `CNF_CMF_3`, `CNF_CMF_4`, `CNF_CMF_5`, `CNF_CMF_6`, `CNF_CMF_7`, `CNF_CMF_8`, `CNF_CMF_9`, `CNF_CMF_10`, `USE_YN`) VALUES (8, 'OLLAMA', 'LLAMA3', 'http://localhost:11434/api/chat', '2024-05-26 17:17:30', NULL, 'llama3', '', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 'Y');

```

```UserConf.properties

    # chat gpt4o 사용시
    #chat.ai.api.group=OPEN_AI
    #chat.ai.api.key=GTP_4_O

    # ollama 모델 사용시
    chat.ai.api.group=OLLAMA
    chat.ai.api.key=LLAMA3
```